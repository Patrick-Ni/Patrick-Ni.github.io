var store = [{
        "title": "",
        "excerpt":"   笔记 links   ","categories": [],
        "tags": [],
        "url": "/articles/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"前置知识   1、NLP任务   根据判断主题的级别, 将所有的NLP任务分为两种类型:      token-level task: token级别的任务. 如完形填空(Cloze), 预测句子中某个位置的单词; 或者实体识别; 或是词性标注; SQuAD等.   sequence-level task: 序列级别的任务, 也可以理解为句子级别的任务. 如情感分类等各种句子分类问题; 推断两个句子的是否是同义等.   nlp任务   2、BERT      十分钟读懂谷歌BERT模型   bert   3、zero-shot one-shot   zero-shot：利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效。zero-shot   one-shot：   4、BERT四大下游任务      句子对分类任务   单句子分类任务   问答任务   单句子标注任务   bert四大下游任务   5、几个标记      [CLS] 标志放在第一个句子的首位，经过 BERT 得到的的表征向量 C 可以用于后续的分类任务。   [SEP] 标志用于分开两个输入句子，例如输入句子 A 和 B，要在句子 A，B 后面增加 [SEP] 标志。   [UNK]标志指的是未知字符   [MASK] 标志用于遮盖句子中的一些单词，将单词用 [MASK] 遮盖之后，再利用 BERT 输出的 [MASK] 向量预测单词是什么。   例如给定两个句子 “my dog is cute” 和 “he likes palying” 作为输入样本，BERT 会转为 “[CLS] my dog is cute [SEP] he likes play ##ing [SEP]”。BERT 里面用了 WordPiece 方法，会将单词拆成子词单元 (SubWord)，所以有的词会拆出词根，例如 “palying” 会变成 “paly” + “##ing”。   bert模型中的[CLS]、[UNK]、[SEP]   6、语言模型 language modeling      标准定义：对于语言序列 ，语言模型就是计算该序列的概率，即  。   从机器学习的角度来看：语言模型是对语句的概率分布的建模。   通俗解释：判断一个语言序列是否是正常语句，即是否是人话，例如  。   https://zhuanlan.zhihu.com/p/52061158   7、prompt learning   prompt是提示的意思，也就是说需要提示模型我们想让它干什么。通常在GPT-3中，我们输入一段描述，再加上“翻译”或者“问答”的prompt，那么GPT-3会生成相应的结果。最近该玩法在NLU中也得到了应用，比如情感分类任务，给定一句话“I missed the bus today.”，在其之后添加一个prompt：“I felt so __”，之后让语言模型用一个情感类的词进行完型填空，再将填空的词语映射到标签，这样一来就能够解决分类任务了。   Prompt Learning-使用模板激发语言模型潜能   8、GPT模型   生成式的预训练   GPT   9、Prompt Tuing   自动构建模板           P-Tuing            Prompt Learning使用模板激发语言模型潜能       10、几个预训练的语言模型（Pre-trained language models）      seq2seq   transformer   GPT   plm   11、前向传播算法和反向传播算法      Forward propagation   Back propagation   link   12、微调   https://www.cnblogs.com/xiaoyh/p/11735686.html   13、实体粒度   https://blog.csdn.net/weixin_33022901/article/details/112106575  ","categories": [],
        "tags": [],
        "url": "/%E7%AC%94%E8%AE%B0/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"记录练手的代码   ","categories": [],
        "tags": [],
        "url": "/Codes/",
        "teaser": null
      },{
        "title": "Papers",
        "excerpt":"一片仍待开拓的荒原   ","categories": [],
        "tags": [],
        "url": "/Papers/",
        "teaser": null
      },{
        "title": "Members",
        "excerpt":"   Piji Li   Xuanfan Ni   Xi Wang   Xiang Zhou   ","categories": [],
        "tags": [],
        "url": "/Members/",
        "teaser": null
      },{
        "title": "Story-generating",
        "excerpt":"        Automated Storytelling via Causal, Commonsense Plot Ordering       通过因果关系、常识情节顺序自动讲故事                       notes                        original                        translation                      ","categories": [],
        "tags": [],
        "url": "/Story-generating/",
        "teaser": null
      },{
        "title": "Prompt-Based",
        "excerpt":"   Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections            notes       original       translation           Prompt-Learning for Fine-Grained Entity Typing            notes       original       translation           Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners            notes       original       translation           Finetuned Language Models Are Zero-shot Learners            notes       original       translation           NSP-BERT: A Prompt-based Zero-Shot Learner Through an Original Pre-training Task —— Next Sentence Prediction            notes       original       translation           PPT: Pre-trained Prompt Tuning for Few-shot Learning            notes       original       translation           ","categories": [],
        "tags": [],
        "url": "/Prompt-Based/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"Automated Storytelling via Causal, Commonsense Plot Ordering   通过因果关系、常识情节顺序自动讲故事   abstract   soft causal relations: causal relations inferred from commonsense reasoning   C2PO: Casual,Commonsense Plot Ordering,一种叙事生成方法，通过因果关系、常识情节排序来实现这一概念（soft casual relation）   Using humanparticipant protocols, we evaluate our system against baseline systems with different commonsense reasoning approaches and inductive biases to determine the role of soft causal relations in perceived story quality. 使用人类参与者协议，我们根据具有不同常识推理方法和归纳偏差的基线系统评估我们的系统，以确定软因果关系在感知故事质量中的作用。   probe the interplay of how changes in commonsense norms across storytelling genres affect perceptions of story quality.探讨不同叙事体裁的常识规范变化如何影响对故事质量的看法的相互作用。   1\tIntroduction   许多先前的情节生成方法都依赖于符号规划(symbolic planning)——以谓词前提和后置的形式直接推理因果支持 -条件匹配。 虽然这些系统可以保证故事事件之间的因果关系，但这些方法也需要广泛的领域知识工程和有限的事件和人物词汇。   自动生成故事的ML方法可以从现有故事或情节摘要的语料库中学习讲故事和领域知识。 这在理论上使他们能够克服知识工程瓶颈。 然而，基于神经语言模型的自动故事生成方法学习单词、句子和事件之间的概率关系，因此难以对动作和事件之间的因果关系进行建模。 此外，故事需要在体裁和常识规范方面保持一致。   In this paper:      将故事生成问题视为情节填充，从源中提取情节点的轮廓，然后对其详细说明。   引入软因果关系的概念，其中故事事件之间的因果蕴涵不需要在逻辑上严格一致，而是借鉴了人们对一个事件是否倾向于在另一个事件之前或之后的日常常识的理解。   在C2PO系统中使用软因果关系填充情节来生成叙事——创建一个可能的故事延续的分支空间，从 COMET 常识推理模型中迭代地提取常识因果推理。 最后，一旦空间——a plot graph——被构建，我们在空间中搜索完整的序列。   根据具有不同用途的常识推理和归纳偏差的基线文本填充系统评估 C2PO，以确定软因果关系对故事质量感知的作用。 我们选择了两个不同类型的故事语料库：现实世界的神秘故事，如福尔摩斯——以通常与日常常识规范一致而闻名，以及儿童童话，如汉塞尔和格莱特——通常打破常识预期的故事。 通过这些研究，我们进一步探讨了更广泛的问题，即不同叙事体裁的常识规范(commonsense norms)的变化如何影响对故事质量的看法。   2\tSoft Casual Relations   Hard Casual Relation   a character John cannot shoot Xavier if John is not in possession of a gun and the two characters are physically co-located.   某些世界状态的改变是非法的   Soft Casual Relation           由假定读者的信念来调节            软因果关系是因果关系——通常是叙事中的逻辑结构——以读者的信念为中介。它从读者的角度而不是从作者的角度提供了事件的因果排序。            对两个非互斥标准的合理预期：             需要某些活动来实现角色的目标：读者试图通过追踪因果关系作为促成因素来理解事件“为什么”发生——某些事件 y 不可能发生，除非某些先前的事件 x 发生。       某些活动是为了追求未来的目标：读者试图通过跟踪和预测角色目标层次结构来理解事情发生的“原因”。           硬因果关系和软因果关系的主要区别在于通过常识推理对因果关系的期望。   Commonsense Knowledge   关于世界如何运作的一组共同共享的知识。它使我们能够对采取某些行动方案时会发生的事情形成预期，并推断过去可能发生的事情。   Commonsense Reasoning   将常识知识应用于特定的上下文   常识推理可用于推断角色达到某种状态可能需要发生的事情（软启动）——以及基于目前发生的事情，合理的下一步行动是什么（软目标）   COMET   模拟假定读者的常识知识。   COMET 是一种基于转换器的语言模型，专为常识推理而设计，并在 ATOMIC 上进行训练。ATOMIC 是一个数据集，其中包含 877k 个与日常常识推理相关的信息实例，这些实例以类型化的 if-then 关系与变量的形式存在。 ATOMIC 被组织成不同的关系类型，例如“需要”、“想要”、“属性”和“效果”。我们专门使用“想要”和“需要”的关系。使用想要关系的原因的一个例子如下，“如果 X 试图逃脱，那么 X 想要自由。”同样，使用需求关系的效果示例是，“如果 X 缩放墙壁，那么 X 需要知道如何缩放墙壁。” 硬因果关系和软因果关系之间的主要区别是通过常识推理对因果关系的期望的想法。硬因果关系需要验证和满足命题，如论文中给出的例子 - 如果约翰没有枪或他们不在同一地点，约翰就不能射击泽维尔。这里的一个软因果关系是读者相信约翰不喜欢泽维尔并想与他战斗，因此他想要武器。枪是武器，因此约翰有可能需要武器来对抗泽维尔。   3\tC2PO   C2PO 首先从给定的文本故事情节 S 中提取一组高级情节点，然后在每个高级情节点之间生成一组分支事件。 通过遍历连接每个生成的子图生成的整体情节图，得到最终的故事。   3.1\t情节提取      使用共指消解(目的在于自动识别表示同一个实体的名词短语或代词，并将他们归类) 和信息提取来识别跟随单个字符的一组情节点。      首先，我们使用预训练的神经共指解析模型提取所有共指集群。可以有多个这样的集群，每个集群都包含故事中属于单个可能角色的所有提及。我们随机选择这些集群之一。让 M = {m1, m2, …, mn} 表示这个集群。同时，我们还使用 OpenIE 从故事文本中提取了一组 &lt;subject、relation、object&gt; 三元组R。一旦我们获得了一个角色的提及集和故事的三元组，我们将它们对齐，尝试根据单个角色在其中的角色级别位置找到与单个角色相关的三元组 P ⊂ R 的子集原始故事文本。神经共指模型和 OpenIE 都是信息检索系统，因此我们可以识别原始故事文本中检索到的信息的字符级偏移或位置。让 pos(·) 成为一个可以做到这一点的函数。   情节点集是 结果是一系列关系元组，其中角色是三元组的主要主题，按它们首次出现在原始故事文本中的时间排序。将每个三元组连接在一起会产生一个主-关系-客短语，我们称之为情节点。   3.2\tPlot Graph Generation      为每对相邻的情节点（pi , pi+1), i ∈ {1, .., n − 1} 然后按照情节点首先出现在 P 中的顺序链接在一起，形成整个故事的情节图。   在相邻的情节点 p1、p2 之间生成情节图：      从 p1 开始，我们使用 COMET 来生成故事中的候选下一个事件。wants关系表示一个直接的前因——一个角色有一个想要的东西，因此执行一个动作。我们递归查询 COMET 以从 p1 开始 n 次生成 k 个候选事件；令其为 $g^{f}$ 。   needs关系表示向后启用——一个角色需要一些真实的东西来做一个动作。我们递归查询 COMET 以从 p2 向后 n 次生成 k 个候选事件；令其为 $g^b$ 。这为我们提供了两个有向无环图。   $g^f$和$g^b$中的关系的加权与 COMET 为每个推理产生的似然分数成正比。                                   下一步是寻找链接$g^f$和$g^b$的最佳方式，并计算到达节点 u ∈ $g^f$ 查看所有节点 ∀v ∈$g^b$的概率。令 $Pr^{needs}(u           v)$ 是 COMET 在needs关系下，以 $e_1$ 为条件,确定的事件 $e_2$ 的发生概率，而 $Pr^{wants}(v           u)$ 是相同但在wants关系下。我们将这个链接的权重定义为：                              $a^{wants}_u$和$a^{needs}_v$是归一化常数（normalization constants）   在这里，我们将它们设置为生成单词“to”的概率，这是两种关系类型共有的 ATOMIC 单词。 对所有节点重复这个过程，直到我们找到一组最佳链接。      最后，我们将整个情节点序列的情节图链接在一起： 。其中 p1, p2 在 P 中是相邻的。一个故事可以是 通过图形从第一个情节点p1 到最后一个 pn 的随机游走生成。 所有随机游走都保证在 pn 终止，因为 $g^b _{pn}$ 是通过从 pn 向后分支构造的。 同样，每个中间情节点 p2…pn−1 是 G 中所有步行必须经过的节点。   5\tExperiments   评估具有两种类型的故事数据集——神秘故事和童话故事   数据以 8:2 的比例划分为训练和测试分割，训练分割用于训练 C2PO 和两个基线模型（如下所述）。从测试集中的每个类型中随机选择 10 个故事集，并按照第 4 节所述提取高级情节点。对于每个模型、每组高级情节点和每个类型，我们生成三个不同的故事总共 3×10×2×3 = 180 个故事。我们为模型、情节点集和类型的每个组合生成三个故事，以解释由于相同的高级情节可以产生的故事的差异C2PO 的分支性质以及基线输出的差异。   总结   这篇论文介绍了soft casual relations这个概念和C2PO的故事生成系统。   软因果关系是指由读者的beliefs来调节的因果关系，从读者的角度提供了事件的因果排序。   两个非互斥标准的合理预期：      需要某些活动来实现角色的目标：读者试图通过追踪因果关系作为促成因素来理解事件“为什么”发生——某些事件 y 不可能发生，除非某些先前的事件 x 发生。   某些活动是为了追求未来的目标：读者试图通过跟踪和预测角色目标层次结构来理解事情发生的“原因”。   然后根据这两个预期，将常识知识应用于特定的上下文形成常识推理，来推断角色达到某种状态可能需要发生的事情（软启动）——以及基于目前发生的事情，合理的下一步行动是什么（软目标）   与之对立的是硬因果关系，硬因果关系需要验证和满足命题   然后引入专为常识推理而设计的COMET的语言转化模型，专门使用“wants”和“needs”的关系。使用想要关系的原因的一个例子如下，“如果 X 试图逃脱，那么 X 想要自由。”同样，使用需求关系的效果示例是，“如果 X 缩放墙壁，那么 X 需要知道如何缩放墙壁。”   最后讲了C2PO生成故事的过程。   首先从给定的文本故事情节 S 中提取一组高级情节点，这个情节点然后在每个高级情节点之间生成一组分支事件。 通过遍历连接每个生成的子图生成的整体情节图，得到最终的故事。  ","categories": [],
        "tags": [],
        "url": "/c2po/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections、   通过对数据集和提示集合进行元调整来适应零样本学习的语言模型   abstract      question：大型预训练语言模型已经获得了执行零样本学习的惊人能力。例如，为了在没有任何训练示例的情况下对情感进行分类，作者可以用评论和标签描述“用户喜欢这部电影吗？”来“提示”LM，并询问下一个词是“是”还是“否”。然而，下一个词预测训练目标仍然与目标零样本学习目标不一致。   solution：元调整  meta-tuning——通过在一组数据集上微调预先训练的语言模型来直接优化零样本学习目标。   1\tIntroduction   zero-shot classification   零样本分类 (ZSC) 的目标是在没有任何示例的情况下使用标签描述对文本输入进行分类。为了将 ZSC 转换为 LM 模型可能表现良好的语言建模 (LM) 任务，最近的许多工作都集中在寻找更好的提示上。   LM 训练目标是相关的，但仍然与回答提示的目标目标不一致。论文通过微调直接优化零样本分类目标来解决这个弱点。这要求：           1) 将不同的分类任务统一为相同的格式            2) 收集分类数据集和标签描述（提示）的集合以进行训练。       论文专注于二元分类任务并将它们统一为“是”/“否”QA 格式，其中输入作为上下文提供，并提供标签信息在问题中。      result shows:      大语言模型（例如 GPT-3）的零样本学习潜力，目前通过上下文提示来衡量，可能被广泛低估了；元调整可能会显着提高它们的性能。   community-wide聚合和统一数据集的努力可以扩大零样本学习模型的培训和评估。   元调整方法可能会激励 LM 推理 API 的提供者收集用户的提示，从而可能导致更大规模的安全、隐私和公平问题。   contributions      使用专家注释的标签描述来管理分类数据集的数据集。   展示训练模型以执行零样本学习的简单方法。   确定提高性能的几个因素；特别是，较大的预训练模型更好。   2\tData   收集分类数据集，并将它们统一为“是/否”问答格式来进行二元分类，并在问题中提供标签信息。对于每个标签，注释1-3个问题。   分类数据集的目标包括但不限于情感分类、主题分类、语法判断、释义检测、定义检测、姿势分类等。体裁包括学术论文、评论、推文、帖子、消息、文章和教科书。   对相似数据集进行分组：           论文目标是测试模型泛化到与训练任务足够不同的任务的能力。因此，在测试时，作者不仅需要排除元调整阶段出现的相同数据集，还需要排除相似的数据集。            两个数据集是否执行相同的任务涉及主观意见，并没有普遍认同的定义。在一种极端情况下，大多数数据集可以算作不同的任务，因为它们具有不同的标签空间和输入分布。在另一个极端，所有数据集都可以被认为是同一个任务，因为它们都可以统一为问答格式。            为了应对这一挑战，论文创建了一组标签，每个标签都描述了一个数据集属性。标签集包括领域分类、文章、情感、社交媒体等。 然后定义如果两个数据集与同一组标签相关联，则它们是相似的，并禁止模型向其中一个学习并在另一个上进行测试。              3 Metrics指标   (1)\tDescriptive statistics描述性统计   对于每个标签描述（问题），通过将“是”答案视为正类来计算 AUC-ROC 分数。在计算每个标签的 AUC-ROC 分数后，作者计算以下一组描述性统计数据比较两个模型。假设模型 Y 假设比 X 更好。将 ∆ 表示为标签描述的 AUC-ROC 从 X 到 Y 的变化，作者可以总结 ∆ 在标签描述集合中的分布情况，统计如下：      作者在此分布中对每个标签描述进行平均加权以计算上述统计量。   论文认为只有当 E[Δ] &gt; 0 和 P[Δ &gt; t] &gt; P[∆ &lt; -t] 对于所有 t ∈ {1%, 5%, 10%}，在所有三种加权类型下，一个模型比另一个模型要好。      4\tModel   (1)\tArchitecture   论文以与 UnifiedQA 相同的方式格式化模型的输入，它将上下文连接到问题并在两者之间添加一个“[SEP]”标记。   然后作者将串联输入concatenated input输入到T5 编码器(Google T5)并通过对第一个解码标记的“是”/“否”概率进行归一化来产生答案分数。除非另有说明，否则论文使用 T5-Large（7.7 亿个参数）初始化模型。   对非 Seq2Seq 预训练模型进行meta-tune，例如 BERT或 RoBERTa，作者在池化输出[pooled input]/“[CLS]”标记之上添加了一个 MLP 层，以在“是”/“否”之间进行分类”。   (2)\tMeta-tuning   论文创建了一个训练分布，在数据集、标签描述和“是”/“否”答案之间取得平衡。   为了创建用于元调整的下一个训练数据点，从训练分割中随机均匀地选择一个数据集（u.a.r.）；然后选择一个标签描述（问题）u.a.r.并以 50% 的概率选择答案为“是”/“否”的文本输入。   为了防止过度拟合，不对标签描述和文本输入的任何组合进行两次训练。对模型进行了 5000 步元调整并使用batch size为 32。   为了评估每个数据集上的 ZSC 性能，作者将一组类似的数据集作为评估集省略，并在其余数据集上进行训练。   5\tResults   5.1\tHypotheses and Conclusions假设和结论           元调整模型在零样本分类中优于一般问答模型。       较大的预训练模型更好。   预训练完成繁重的工作。   性能可以通过对类似数据集进行训练、使用 QA 模型进行初始化或集成标签描述来提高。   提前停止对性能至关重要。      5.2\tRobustness Checks   将 60M 参数模型与 220M 参数模型进行了比较，发现后者要好得多。然而，一个问题是作者的模型是用 T5 初始化的，它在开放网络上训练并且可能已经看到了作者收集的数据集。因此，更大的模型可能更好，因为它们更擅长记忆。   6\tDiscussion and Future Directions   (1)\tMain takeways   本文构建了一个分类数据集，以通过元调整使语言模型适应零样本分类(ZSC)。适应模型优于通用问答模型和基于自然语言推理的现有技术。作者预测元调整在更大的模型上会更有效，而当前零样本学习的工程上限可能被广泛低估。   (2)\tAggregating and unifying datasets   研究难点：      寻找新的NLP任务   为每个数据集手动编写程序来转换为所需的格式   很难仅仅通过数据集的来源来判断数据集的质量，有时需要手动检查数据集。   (3)\tMeta-tuning as a probe   测量 GPT-3 等大型语言模型的智力或少样本学习能力兴趣越来越大。然而，由于这些模型不适用于回答这些提示，作者怀疑其执行小样本学习的知识和真正潜力比报告的要高得多。由于预训练完成了繁重的工作，元调整不太可能为模型提供额外的 ZSC 能力，因此我们可能首先使用元调整作为探针，使它们在测量其性能之前适应回答提示。   (4)\tBeyond Shallow Correlations   一种可能性是该模型仅从元调整中学习浅层统计相关性，而不是“更复杂的推理技巧”。例如，“令人兴奋”一词可能更多地出现在正面评论中。这不太可能，因为较大的模型始终比较小的或随机初始化的模型更好。为了解释这种性能差距，较大的模型必须学会在元调整期间使用更复杂的特征。   (5)\tRelation to Meta/Multitask-Learning   模型不会从任何目标任务示例中学习。此处的meta”并不意味着“meta-learning”，而是反映了模型从任务的元数据集中学习的事实。   (6)\tAnnotating Prompts   标注匹配目标用户分布的提示将是一个重要的研究方向。   此外，更短、更自然的描述有时无法准确捕捉标签的语义。例如，“医疗”标签的描述是“人们需要医疗援助”；或者，它可以更长但更准确：“人们需要支持医生和其他卫生专业人员工作的联合卫生专业人员”。如何在没有专家的努力下可扩展地生成更准确和详细的标签描述将是另一个未来方向。   (7)\tOptimizing Prompts   本文的工作是对最近优化提示以实现更高准确性的工作的补充。即使元调谐模型专门用于回答提示，它对不同提示的反应仍然可能非常不同。例如，在立场分类数据集中，为同一个标签标注了两个标签描述（提示）：“这篇文章支持无神论吗？”和“这篇文章反对有宗教信仰吗？”。它们具有相似的含义，但前者的准确性比后者低得多。作者推测这是因为该模型无法为“无神论”等抽象概念提供依据。  ","categories": [],
        "tags": [],
        "url": "/201404670/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"Prompt-Learning for Fine-Grained Entity Typing   细粒度实体类型的Prompt-learning   abstract      通过使用完形填空式的语言提示来激发 PLM 的潜能，提示学习可以在自然语言推理、情感分类和知识探测等一系列 NLP 任务上取得可喜的成果。   本文研究了提示学习在全监督、少样本和零样本场景中的细粒度实体类型中的应用。   为了解决零样本制度，作者提出了一种自监督策略（self-supervised strategy），该策略在提示学习中进行分布级别优化，以自动汇总实体类型的信息。   在完全监督、少样本和零样本设置下对三个细粒度实体类型基准（最多 86 个类）进行的大量实验表明，Prompt learning方法显着优于微调基线，尤其是在训练数据不足时。   1\tIntroduction   近年来，预训练语言模型 (PLM) 得到了广泛的探索，并成为自然语言理解和生成的关键工具。研究人员的许多努力都致力于激发 PLM 中的特定任务知识，并将这些知识应用于下游 NLP 任务。 使用额外分类器进行微调一直是使 PLM 适应特定任务的一种典型解决方案，并在各种 NLP 任务上取得了有希望的结果。   最近在探索 PLM 知识方面的一些努力表明，通过编写一些自然语言提示，我们可以诱导 PLM 完成事实知识。 GPT-3 进一步利用提示提供的信息进行小样本学习并取得了惊人的结果。受此启发，引入了Prompt-learning。在提示学习中，下游任务被形式化为等效的完形填空式任务，并且要求 PLM 处理这些完形填空式任务而不是原始下游任务。   在这项工作中，作者全面探索了提示学习在全监督、少样本和零样本设置中的细粒度实体类型中的应用。      本文首先引入了一个简单的管道，在那里构建了面向实体的提示，并将细粒度的实体类型化为一个完形填空式的任务。   然后，为了解决在训练中不存在明确监督的零样本场景，作者在管道下开发了一种自我监督的策略，试图通过优化提示学习中成对示例的预测概率分布的相似性来自动总结实体类型。   实验使用了三个流行的基准，包括 FEW-NERD、OntoNotes 、BBN。 所有这些数据集都具有复杂的类型层次结构，包含丰富的实体类型，要求模型具有良好的实体属性检测能力。   2\tBackground   2.1\tProblem Definition   实体类型的输入是一个数据集 $\\mathcal{D} = {x_1, …, x_n}$， 有 n 个句子，每个句子 x 包含一个标记的实体mention（实体提及）m。   对于每个输入句子 x，实体类型旨在预测其标记提及 m 的实体类型 $y ∈ \\mathcal{Y}$，其中 $\\mathcal{Y}$ 是一组预定义的实体类型。   实体类型通常被视为上下文感知分类任务。 例如，在句子“伦敦是耶稣琼斯摇滚乐队的第五张专辑…”中，实体提及伦敦应归类为音乐而不是位置。 在 PLM 时代，使用预训练的神经语言模型（例如 BERT）作为编码器并执行模型调整以进行类型分类成为标准范式。   2.2\tVanilla Fine-tuning   对于输入序列$x={[CLS],t_1,…,m,…t_T,[SEP]}$中的每个带有实体提及$m={t_i,…,t_j}$的token $t_i$，PLM生成其上下文化的表示${h_{[CLS]},h_1,…,h_T,h_{[SEP]}}$ 。根据经验，选择token [CLS]的嵌入（embedding）作为输入输出层的最终表示：                     这里W和b是可学习参数。 W、b 和 PLM 的所有参数通过最大化目标函数$\\frac{1}{n} \\sum_{i=1}^{n}\\log{(P(y_i       s_i))}$，其中$y_i$是$s_i$的golden type label。           2.3\tPrompt-based Tuning   在基于提示的调优中，对于每个标签 $y ∈ \\mathcal{Y}$，我们定义了一个标签词集 $\\mathcal{V}_y = {w_1, . . . , w_m}$。 $\\mathcal{V}_y$ 是 PLM $\\mathcal{M}$ 的词汇表 $\\mathcal{V}$ 的子集，即 $\\mathcal{V}_y ⊆ \\mathcal{V}$。 通过取每个标签对应的字典的并集，我们得到一个整体字典 $\\mathcal{V}^ ∗$ 。 例如，在情感分类中，我们可以将标签 y = POSITIVE 映射到集合 $\\mathcal{V}_y = {great, good, beautiful…}$。   提示学习的另一个主要组成部分是提示模板 $T(·)$，它通过在 x 的末尾添加一组附加标记将原始输入 x 修改为提示输入 T(x)。 传统上，为 PLM 添加 [MASK] 标记以预测丢失的标签词 $w ∈ \\mathcal{V}^∗$ 。 因此，在提示学习中，分类问题被转换为掩码语言建模问题。      3\tPrompt-learning for Entity Typing: A Naive Pipeline   本节首先介绍一个朴素但经验丰富的基线，它利用提示提取具有显式监督的实体类型，包括标签词的构建（第 3.1 节）、模板（第 3.2 节）和训练（第 3.3 节）。 这样一个简单的管道在三个基准数据集上产生了显着的结果。 然后我们提出了一种自监督的提示学习方法，可以从未标记的数据中自动学习类型信息（第 3.4 节）。   3.1\tLabel Words Set $\\mathcal{V}^*$   对于细粒度的实体类型，数据集通常使用分层标签空间，例如 PERSON/ARTIST 和 ORGANIZATION/PARTY。在这种情况下，我们使用所有词作为该实体类型的标签词集 $\\mathcal{V}^*$。 例如，y = LOCATION/CITY → v = {location, city}。   在掩码语言建模中，我们使用 $\\mathcal{V}_y$ 中所有单词的置信度分数来构建特定类型 y 的最终分数。对于输入 x（映射到 T(x)）及其实体类型 y（映射到 $\\mathcal{V}_y = {w_1, …, w_m}$），条件概率变为      其中 $λ_i$ 是一个参数，表示当前词 $w_j ∈ \\mathcal{V}_y$ 的重要性。   3.2\tTemplates   (1)\thard-encoding templates   我们选择简单的声明性模板而不是上位词模板来避免语法错误。   在硬编码设置的模板中，我们首先复制 x 中标记的实体提及，然后添加一些链接动词和文章，然后是 [MASK] 标记。 使用标记实体提及 [Ent].      (2)\tsoft-encoding templates   引入了一些额外的特殊标记 [P1], …, [Pl] 作为模板，其中 $l$是一个预定义的超参数。 模板以分隔符 [P] 和实体提及 [M] 的副本开头。      其中每个提示嵌入在训练期间随机初始化和优化。   3.3\tTraining and Inference   硬编码或软编码的策略提供不同的模板初始化，它们都可以通过 φ 参数化并在训练过程中与 M 一起优化。 我们使用交叉熵损失函数训练预训练模型 M（由 θ 参数化）以及附加提示嵌入：      该管道可以应用于具有显式监督的实体输入任务，即使训练数据不足，即少样本场景也有效。 自然，我们考虑更极端的情况，即没有任何训练数据的场景（零样本场景）。在这种设置下，如果我们直接使用一个额外的分类器来预测标签，结果相当于随机猜测，因为分类器的参数是随机初始化的。 如果我们根据预测词使用提示来推断标签，虽然其性能明显优于猜测，但也会出现灾难性的下降。 这时候就出现了一个问题：“PLM 是否可以在没有任何明确监督的情况下预测实体类型？ ”   4\tSelf-supervised Prompt-learning for Zero-shot Entity Typing   零样本实体类型的自监督提示学习   对于提示学习，答案是肯定的，因为在预训练阶段，实体的上下文已经暗示了相应的类型信息，这为提示学习范式提供了有利的初始化点。 例如，在带有 T3模板的输入句子中：“Steve Jobs found Apple. 在这句话中，史蒂夫乔布斯是一个[MASK]”。 在我们的观察中，PLM 预测masked位置的人的概率将显着高于位置的概率。 而如果我们合理利用这个优越的初始化点，PLMs就有可能自动汇总类型信息，最终提取出正确的实体类型。   4.1\tOverview   考虑一种自监督范式，该范式优化了由相似示例预测的概率分布在投影词汇 $\\mathcal{V}^*$ 上的相似性。为了在提示学习中实现这一点，需要：      对模型的预测范围施加限制   供一个未标记的数据集，其中实体mention 被标记为没有任何类型，以允许模型以自监督的方式学习诱导类型信息的过程。   输入包含一个预训练的模型 $\\mathcal{M}$、一个预定义的标签模式 $\\mathcal{Y}$ 和一个没有标签的数据集 $\\mathcal{D} = {x_1, …, x_n}$（实体提及被标记为没有任何类型）。我们的目标是让 $\\mathcal{M}$ 在 $\\mathcal{D}$ 和 $\\mathcal{Y}$  上训练后能够自动进行零样本实体打字。   使用提示学习作为训练策略，我们首先从 $\\mathcal{Y}$构建一个标签词集 $\\mathcal{V}$，对于 \\mathcal{D} 中的每个句子 x，我们用带有 [MASK] 符号的硬编码模板包装它。关键思想是使同类型实体在 $\\mathcal{V}^$ 上的预测分布尽可能相似。这样，我们可以通过对正负示例进行采样来进行对比学习，同时忽略不在$\\mathcal{V}^*$中的其他词对 MLM 过程中优化的影响。   4.2\tSelf-supervised Learning   基于一个简单的假设制定抽样策略，即不同句子中的相同实体具有相似的类型。优化单词在$\\mathcal{V}^*$ 上的分布之间的相似性。这种策略不仅软化了监督，而且消除了自监督学习中其他词的影响。   本文从一个大规模的实体链接中语料库 D中随机抽取了c对正对，即共享一个相同实体mention的句子对，表示为$\\hat{\\mathcal{D}{pos}}$，以及c对负对，即标记了不同实体mention的两个句子，表示为$\\hat{\\mathcal{D}{neg}}$ 。为了避免产生假负样本，负样本进一步被包含公共实体及其类型信息的大字典限制。 仅选择字典中具有不同类型实体的句子对作为负样本。 然后用硬编码 T3(·) 包裹它们。 为了避免实体名称的过度拟合，我们使用概率为 α 的特殊符号 [Hide] 随机隐藏实体提及（在原始输入和模板中）。 根据经验，α 设置为 0.4。   由于一对示例对训练的影响应该在分布级别进行衡量，因此我们选择 Jensen-Shannon 散度作为评估两个分布相似性的指标。 因此，在一个句子对 $(x, x’ )$ 中，[MASK] 位置的预测 $h$ 和 $h’$ 的两个表示的相似性分数计算如下：                     其中 JS 是 Jensen-Shannon 散度，$P_{V^*} (w       x)$ 和 $P_{V^*} (w       x’)$ 是通过 h 和 h’ 获得的预测标记 $w$ 对 $V^∗$ 的概率分布。           当为了使正对的预测相似时，目标是通过以下方式计算的：      其中 γ 是惩罚项，因为假设在负对中是松散的。   5\tExperiments   5.1\tDatasets   FEW-NERD、OntoNotes 和 BBN。   5.2\tExperimental Settings   实验在三种不同的设置下进行。      Supervised Setting： 在完全监督的设置中，所有训练数据都用于训练阶段。FT 和 PLET 用于训练模型。 我们使用 BERT的base-cased 主干在所有三个数据集上运行实验。 硬编码和软编码都用于 PLET。   Few-shot Setting：为每个实体类型随机抽取 1、2、4、8、16 个实例进行训练。在所有三个数据集上都应用了硬编码的 FT 和 PLET 方法。   Zero-shot Setting：仅对 PLET 和 PLET (S) 进行实验。   指标：沿用了 Ling and Weld  广泛使用的设置。   5.3\tResults      Fully Supervised Entity Typing：         Few-shot Entity Typing：         Zero-shot Entity Typing：      5.4\tEffect of Templates      模板的选择对基于提示的小样本学习的性能产生了相当大的影响。   对于硬编码模板，描述“在这句话中”位置的短语有助于显着提高性能。   对于软编码模板，提示学习模型以最少的特殊标记产生了最好的结果。   6\tConclusion      研究了提示学习在细粒度实体类型中的应用。 本文提出了一个框架 PLET，可以在完全监督、少样本和零样本场景中处理细粒度实体类型。   在 PLET 中，作者首先引入了一个简单有效的提示学习管道，可用于提取具有充分监督和不充分监督的实体类型。 此外，为了处理零样本设置，作者提出了一种自监督的提示学习方法，该方法基于未标记的语料库和预定义的标签模式自动学习和总结实体类型。   PLET 利用提示来利用分布在 PLM 中的先验知识，并且可以通过执行分布级别优化来学习预定义的类型信息而不会过度拟合。  ","categories": [],
        "tags": [],
        "url": "/201810604/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners   可区分提示使预训练语言模型更好   Abstract   大规模预训练语言模型通过展示作为少样本学习者的卓越能力，对自然语言处理做出了重大贡献。然而，它们的有效性主要取决于模型参数的缩放和快速设计，阻碍了它们在大多数实际应用中的实现。   本研究提出了一种名为 DifferentiAble pRompT (DART) 的新型可插拔、可扩展和高效方法，该方法可以将小型语言模型转换为更好的少样本学习器，而无需任何提示工程。这种方法背后的主要原理涉及将潜在的自然语言处理任务重新构建为预训练语言模型的任务，并通过反向传播对提示模板和目标标签进行差异化优化。   此外，所提出的方法可以是：      插入任何预先训练的语言模型；   扩展到广泛的分类任务。   对标准 NLP 任务的综合评估表明，所提出的方法实现了更好的少拍性能(few-shot performance)。   1\tIntroduction   (1)\t存在的问题   大规模预训练模型面临小样本学习(few-shot learning)的挑战。   (2)\t已有的解决方法   一种新型微调方法，可以为较小的语言模型 (LM) 配备少量功能：通过完成完形填空任务，将预训练的 LM 直接用作预测器，它将下游任务视为masked language modeling problem。这些提示可用于微调，为分类器提供额外的任务信息，尤其是在低数据情况下。   难点：获得优化的提示模板和目标标签标记并非易事。   (3)\t本文提出的方法   DART，可区分提示的微调方法。关键思想是利用语言模型中的一些参数（未使用的标记）作为模板和标签标记，并使用反向传播在连续空间中优化它们。   本文提出了一个两阶段的优化算法，首先是学习模板和标签，然后是整体参数。进一步引入了一个辅助流畅性约束对象来确保提示嵌入之间的关联。      2\tRelated Work   Language Modeling Prompt：最近在该领域进行的研究一直专注于自动搜索提示。      提出了 PET，它将 NLP 任务重新制定为完形填空式问题并执行基于梯度的微调。   在微调期间使用更密集的监督对象改进 PET。   建议使用 AUTOPROMPT 为基于梯度引导搜索的各种任务创建提示。   提出了一种称为 PTR 的方法，它利用逻辑规则为多类文本分类构造带有子提示的提示。   将潜在的 NLP 任务重新表述为一个蕴涵任务，然后用少量样本对模型进行微调。   提出了一种通过校准将外部知识图整合到语言表达器中的方法。   提出了 LM-BFF——更好的语言模型的少量微调，它利用 T5 [35] 在词汇表中生成模板和搜索标签标记。   然而，使用生成模型和带有验证的标签搜索是计算密集型的。此外，由于神经网络的连续性，对离散空间的快速搜索是次优的。   为了克服这些限制：      提出了 P-tuning，它采用了由 LSTM 学习的可训练的连续提示嵌入。   提出了一种称为 OPTIPROMPT 的有效连续方法来优化事实探查的提示。   提出前缀调整，它保持语言模型参数冻结，但为自然语言生成任务优化了一个小的连续任务特定向量。   提出了一种学习“软提示”的机制，以调节冻结语言模型以执行下游任务。   然而，这些方法仍然需要优化外部参数（例如 P-tuning 中的 LSTM）并且容易出现复杂的标签空间。   3\tBackgroud   3.1\tLanguage Model Prompt   设 $X_in = {x_1, x_2,…, x_L}$ 是一个句子，其中 $x_i$ 是输入句子中的第 i 个token，L 是token的数量。 具体来说，$X_in$ 被转换为一个固定的标记序列 $\\tilde{x_{in}}$，然后映射到一个隐藏向量序列 ${h_k ∈ \\mathbb{} d}$。 给定输入序列 $\\tilde{x_{in}} = [\\mathbf{CLS}]X_{in}[\\mathbf{SEP}]$，传统的微调方法利用 [CLS] 嵌入（例如，MLP 层）上的通用头层来预测输出类。 对于基于提示的方法，特定任务的模式字符串（模板 $\\mathcal{T}$ ）旨在诱导模型生成对应于给定类（标签标记 $\\mathcal{M} (Y)）$的文本输出——我们将这两件事一起称为一个提示。 具体来说，包含一个 [MASK] token的 $X_prompt$ 直接将 MLM 输入分配给以下任务：                     当提示输入MLM时，模型可以得到候选类的概率分布$p([MASK]       (X_{prompt})$，y∈Y为：              其中 w 表示第 y 类的第 w 个标签标记。   4\tOur Approach   4.1\tMotivation   少样本学习者的预训练语言模型的改进，需要最佳提示。   4.2\tDifferentiable Template Optimization   给定模板：$\\mathcal{T}={[\\mathbf{T}{0:i}],[\\mathbf{MASK}],[\\mathbf{T}{i+1:j}]}$，满足$[\\mathbf{T}_i]\\in\\mathcal{V}$，并将模板映射为：      DART 将$ [\\mathbf{T}_i]$ 视为伪标记并将模板映射如下：      其中$ h_i(0 ≤ i ≤ j) $是可训练的参数。 可微模板优化可以获得超出原始词汇表$\\mathcal{ V}$ 的表达模板。 最后，模板$h_i$ 通过以下方式进行了差异优化：      提示嵌入的值 $h_i$ 必须相互依赖而不是独立。   4.3\tDifferentiable Label Optimization   基于提示的微调需要填写一个单词，并将被屏蔽的单词预测映射到一个语言器，生成一个类（即“是”：真。“否”：假）。对于每个类 $c ∈ Y$，之前的方法估计初始 L 在前 k 个词汇词的修剪集$\\mathcal{ V}^ c ⊂V $上的条件似然。   然而，蛮力标签搜索：（1）计算量大且繁琐，因为 $\\mathcal{D}_{dev}$ 通常非常大，需要多轮评估。 (2)随着类数的增加，可扩展性差（很多分类数据集有100多个类），搜索次数可能是$k^C$（C代表类的总数），这是指数级的，因此难以处理。此外，类的标签包含丰富、复杂的语义知识，一个离散的标记可能不足以表示这些信息。   具体来说，对于标签 $Y = {Y_1,Y_2,..,Y_m}$，不同于之前将类type  $Y_i$ 转换为可变数量的标签标记 ${…,v_1,..,v_k ,. ..}$，DART 将 $Y_j$ 映射到一个连续的词汇空间：      其中$\\mathcal{ M }$是模板中可训练嵌入的数量。 为避免优化任何外部参数，将 ${h_1,…,h_m,..,h_{m+n}}$ 替换为 $\\mathcal{V}$ 中未使用的标记以生成$\\mathcal{V}’$。   4.4\tTraining Objectives   类别区分目标 $\\mathcal{L}_C$ 和流畅性约束目标 $\\mathcal{L}_F$。   (1)\tclass discrimination object      其中 CE 是交叉熵损失函数，$\\mathcal{L}_C$ 代表类别区分损失。   (2)\tFluency Constraint Object                  输入句子中的一个 token 被随机屏蔽，并进行屏蔽语言预测。 $x$ 和 $x’$ 分别是原始序列和掩码序列。 设 $x^m$ 为在 $x’$ 中被屏蔽的目标标记，$P(x^m       x’ , y)$ 最大化如下：              通过优化$\\mathcal{L}_F$ ，语言模型可以获得更好的上下文表示，模板标记之间具有丰富的关联。 我们有以下训练对象：         4.5 Comparison to Previous Prompt-tuning Approaches      5\tExperiments   5.1 Dataset Statistics   对 15 个 NLP 任务进行了全面研究，涵盖了情感分析、自然语言推理、释义、句子相似性、关系提取和事件提取。评估包括 10 个流行的句子分类数据集。   5.2\tSettings           使用Pytorch实现模型。            使用与LM-BFF相同的设置：使用一组固定的种子Sseed测量每个任务的五个不同采样Dtrain的平均性能。       使用AdamW作为优化器。   我们使用 RoBERTa-large 对分类任务进行实验，以便与 LM-BFF 进行公平比较。   使用uncased BERT-large [10] 来进行关系提取数据集。   5.3\tMain Result      5.4\tAblation Study   消融研究      在缺少任何一个模块（即流畅性约束对象、可微模板或可微标签）的情况下，DART 表现出性能下降，这表明所有模块都是有利的。   可微标签优化对性能更敏感，并且对 DART 非常有益，尤其是对于低资源设置。   5.5\tAnalysis and Discussion   (1)\tCan DART Applied to Other Pre-trained LMs?   DART 可以应用于其他预训练的语言模型吗？      使用 GPT-2 介质的 DART 比传统的微调方法产生更好的性能。此外，论文注意到使用 GPT-2-medium 的 DART 可以达到与 BERT-large 相当的性能。   (2)\tWhat Exactly Optimized Prompt is?   什么是完全优化提示？   作者进行最近邻词汇嵌入搜索，将 $\\mathcal{V}$ 中的 Top-3 优化伪标签标记投射到可读的自然语言中。   使用 t-SNE [43] 和标准化来可视化 Wiki80 数据集上的标签。      (3)\tDART v.s. Conventional Fine-tuning      DART 没有优化任何新参数；然而，传统的微调应该在 [CLS] 嵌入上学习一个明确的分类器，这在低数据情况下可能会失败。   DART 具有与大规模语言模型预训练相同的任务设置，并且对于下游分类任务具有较小的理论上限。   (4)\tLimitations   当任务语料库的分布与预训练语料库的分布不同时，DART可能会失败。此外，DART还显示了与超参数相关的不稳定性， NLP 中少样本学习的波动性。   6\tConclusion and Future Work   本文介绍了 DART，这是一种简单而有效的微调方法，可改进快速学习预训练语言模型。与传统的微调方法相比，所提出的方法可以在少拍场景中产生令人满意的改进。所提出的方法也可用于其他语言模型，并可扩展到其他任务，例如意图检测。直观地说，本研究中获得的结果可用于激发 NLP 小样本学习的两个未来研究方向：      将所提出的方法扩展到半监督设置以进一步利用未标记数据；   将所提出的方法扩展到少拍终身学习，而提示必须通过自适应任务进行优化。   ","categories": [],
        "tags": [],
        "url": "/210813161/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS   微调语言模型是零样本学习器   abstract   本文探索了一种提高语言模型零样本学习能力的简单方法：指令调优——在通过指令描述的一系列任务上微调语言模型——FLAN指令调整模型。   1\tIntroduction           大规模的语言模型 (LM)，例如 GPT-3，已被证明可以非常好地执行few-shot Learning。然而，他们在零样本学习方面不太成功，一个潜在的原因是，如果没有少量样本，模型很难在与预训练数据格式不相似的提示上表现良好。            本文探索了一种简单的方法来提高大型语言模型的零样本性能。想法来自于NLP 任务可以通过自然语言指令来描述，本文采用 137B 参数的预训练语言模型并执行指令调优——在通过自然语言指令表达的 60 多个 NLP 任务的混合上对模型进行微调。模型称为 Finetuned LANguage Net，或 FLAN。            本文根据 NLP 任务的任务类型将它们分组到集群中，并在对所有其他集群进行指令调整 FLAN 的同时，将每个集群用于评估。评估表明，FLAN 显着提高了基本 137B 参数模型的零样本性能。            消融研究发现在指令调整中增加任务集群的数量可以提高看不见的任务的性能，并且指令调整的好处只有在模型规模足够大的情况下才会出现。            本文实证结果强调了语言模型执行使用自然语言指令描述的任务的能力。指令调优结合了预训练-微调和提示范式的吸引人的特征，通过微调使用监督来提高语言模型响应推理时间文本交互的能力。       2\tFLAN: INSTRUCTION TUNING IMPROVES ZERO-SHOT LEARNING   通过使用监督来教 LM 执行通过指令描述的任务，它将学会遵循指令，同时可以拓展到unseen tasks上。   2.1\tTASKS &amp; TEMPLATES   将 62 个在 Tensorflow Datasets 上公开可用的文本数据集（包括语言理解和语言生成任务）聚合到一个单一的混合物中，每个数据集被归类为12个任务集群之一，给定集群中的数据集属于相同任务类型。   将任务定义为由数据集给出的一组特定的输入-输出对。对于每个任务，作者手动编写十个独特的模板，使用自然语言指令描述任务，且最多包含三个模板来“扭转任务”。(e.g.对于情感分类，我们包含要求生成负面电影评论的模板)   在所有任务的混合上对预训练的语言模型进行指令调整，每个任务中的示例通过为该任务随机选择的指令模板格式化。   任务集群：      2.2\tEVALUATION SPLITS   如何定义unseen task？      先前的工作通过禁止在训练中出现相同的数据集来对unseen task进行分类。   如果 $\\mathcal{T}$ 是一个蕴涵任务，那么指令调整数据集中没有出现任何蕴涵任务，对来自所有其他集群的任务进行指令调整。   2.3\tCLASSIFICATION WITH OPTIONS   对于分类任务，之前的任务只考虑两个输出“是/否”。本文包含一个选项后缀，将token OPTIONS 与该任务的输出类列表一起附加到分类任务的末尾， 这使模型知道在响应分类任务时需要哪些选择。   2.4\tTRAINING DETAILS   (1)\tModel architecture and pretraining.   本次实验使用密集的从左到右、仅解码器的 137B 参数转换器语言模型，在一组 Web 文档（包括那些带有计算机代码的文档）、对话数据和维基百科上进行预训练。将预训练的模型称为Base LM。   (2)\tInstruction tuning procedure.      将每个数据集的训练示例数量限制为 30,000。   为了防止少训练示例的数据集被边缘化，实验遵循示例比例混合方案，最大混合率为 3000。   微调使用 Adafactor Optimizer， 以 3e-5 的学习率、 8,192 的批量大小进行 30,000 次梯度更新的所有模型。   微调过程中使用的输入和目标序列长度分别为 1024 和 256。   将多个训练示例组合成一个序列，使用特殊的序列结束标记将输入与目标分开。   3\tRESULTS   本节在自然语言推理、阅读理解、开放域 QA、常识推理、共指解析和翻译等任务上评估 FLAN。   3.1\tNATURAL LANGUAGE INFERENCE      自然语言推理的结果。 对于 FLAN，我们报告了最多 10 个模板的平均值（在没有及时工程的情况下代理预期性能），以及在开发集上具有最高性能的模板的测试集性能。 三角形 N 表示对少拍 GPT-3 的改进。 向上箭头 ↑ 表示仅比零样本 GPT-3 , T5-11B，BERT-large有所改进。   3.2\tREADING COMPREHENSION &amp; OPEN-DOMAIN QA      阅读理解和开放域问答的结果。  三角形 N 表示对少拍 GPT-3 的改进。 向上箭头 ↑ 表示仅比零样本T5-11B、 GPT-3 有所改进。   3.3\tCOMMONSENSE REASONING &amp; COREFERENCE RESOLUTION      常识推理和共指解析的结果（精度为 %）。 T5-11B，bBERT-large， 三角形 N 表示对少拍 GPT-3 的改进。 向上箭头 ↑ 表示仅比零样本 GPT-3 有所改进。   3.4\tTRANSLATION      WMT’14 En/Fr 和 WMT’16 En/De 和 En/Ro 的转换结果 (BLEU)。 三角形 N 表示对少拍 GPT-3 的改进。 向上箭头 ↑ 表示仅比零样本 GPT-3 有所改进。   4\tABLATION STUDIES &amp; FURTHER ANALYSIS   4.1\tNUMBER OF INSTRUCTION TUNING CLUSTERS   在第一次消融中，本文研究了指令调优中使用的集群和任务数量对性能的影响，将 NLI、开放域 QA 和常识推理作为评估集群，并使用剩余的 7 个集群进行指令调整。         三个保留集群的平均性能随着我们向指令调整（情感分析集群除外）添加额外的集群和任务而提高。   测试的七个集群，性能似乎没有饱和，这意味着性能可能会随着指令调整中添加更多集群而进一步提高。   尽管从情感分析集群中看到了最小的附加值，但这种消融不允许我们得出关于哪个指令调整集群对每个评估集群贡献最大的结论。   4.2\tSCALING LAWS   探讨指令调整的好处如何受模型规模的影响，评估了指令调整对大小为 422M、2B、8B、68B 和 137B 参数的模型的影响。      对于held-out任务：      对于100B 参数数量级的两个模型，指令调整显着提高了性能。   对于 8B 和更小的模型，指令调整实际上会损害保持任务的性能。   对这一结果的一个潜在解释可能是，对于小规模模型，学习指令调整期间使用的 40 个任务会填满整个模型容量，导致这些模型在新任务上的表现更差。对于更大规模的模型，指令调整填充了一些模型容量，但也教会了这些模型遵循指令的能力，允许它们利用剩余容量泛化到新任务。   4.3\tINSTRUCTION TUNING FACILITATES PROMPT TUNING   指令调优提高了模型响应指令的能力，因此，如果 FLAN 确实更适合执行 NLP 任务，那么它也应该在使用通过提示优化的连续提示执行推理时获得更好的性能调优。      上表显示了使用全监督训练集和仅具有 32 个训练示例的低资源设置的这些快速调整实验的结果。在所有场景中，FLAN 的快速调优效果比 Base LM 更好。在很多情况下，特别是对于低资源设置，FLAN 上的即时调优甚至比 Base LM 上的即时调优提高了 10% 以上。这个结果以另一种方式举例说明了指令调整如何产生一个更适合执行 NLP 任务的检查点。   5\tDISCUSSION   论文探讨了零样本提示中的一个简单问题：指令调整语言模型是否会提高其执行未知任务的能力。在 FLAN 上的实验表明，指令调优提高了针对未调优模型的性能，并在我们评估的大多数任务上超过了零样本 GPT-3。通过消融研究，发现随着指令调整中使用的任务集群数量的增加，unseen task的性能会提高，而且有趣的是，指令调整的好处只有在模型规模足够大的情况下才会出现。此外， FLAN 似乎比未修改的基本模型对即时调整的响应更好，证明了指令调整的额外好处。   本文中显示的结果为未来的研究提出了几个有希望的方向：      可以通过更多指令调整任务来进一步提高性能，这些任务可以以自我监督的方式生成。   探索多语言环境也很有价值，例如，人们可以问，在高资源语言中对监督数据进行指令调整是否会提高低资源语言中新任务的性能。   具有监督数据的指令调整模型也可能用于改善模型在偏见和公平方面的行为。   6\tCONCLUSION   本文探讨了指令调优。我们提出了 FLAN，这是一个 137B 参数语言模型，它执行使用指令描述的 NLP 任务。通过利用微调的监督来提高语言模型响应教学提示的能力，FLAN 结合了预训练-微调和提示范式的吸引人的方面。 FLAN 的性能优于零样本和少样本 GPT-3，表明大规模模型遵循指令的潜在能力。我们希望我们的论文能够推动对零样本学习和使用标记数据改进语言模型的进一步研究。   ","categories": [],
        "tags": [],
        "url": "/210901652/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"NSP-BERT: A Prompt-based Zero-Shot Learner Through an Original Pre-training Task —— Next Sentence Prediction   NSP-BERT：通过原始预训练任务的基于提示的零样本学习器——下一句预测   1\tIntroduction      论文主要贡献：      NSP-BERT 在不使用任何特定任务的训练数据的情况下，在零样本模型中实现了 SOTA 性能。   提出了两种替代的label/answer mapping方法。   使用软定位和两阶段提示构建方法来缓解基于句子级提示的模型对标记位置不敏感的问题。   证明了一个简单的基于交互模型的句子级对比学习预训练任务可以很好地适应基于提示的学习并解决各种 NLP 任务。   2\tRelated Work   一些关于zero-shot 和few-shot的prompt-learning的模型和任务。           MLM/L2R LM：token-level prompt-learning methods。       Sentence-Level Prompt-Learning **：EFL**将 NLP 任务重新表述为 sentence entailment-style tasks。输入/标签对：”x: [CLS] The Italian team won the European Cup. [SEP] This is Sports news.[EOS], y: Entail”。 EFL 模型可以在少样本学习上表现良好，但在零样本任务上表现不佳。   Automated Prompt：自动搜索，生成提示。LMBFF模型使用条件似然自动选择标签词，并使用 T5 生成模板。 AUTOPROMPT **使用梯度引导搜索来创建提示。 与上述离散提示搜索方法相比，P-tuning** 采用可训练的连续提示嵌入，通过 P-tuning，GPT 在监督学习中实现了与类似大小的 BERT 相当甚至更好的性能。   optimization methods in prompt-learning：ADAPET通过在完整的原始输入上分离label token的损失和label-conditioned的 MLM 目标来使用更多的supervision。 PTR结合了逻辑规则，用几个简单的子提示来组成特定于任务的提示。指出 GPT 中存在 3 种类型的偏差（多数标签偏差、新近偏差和普通标记偏差）。 通过使用无内容输入（例如“N/A”）来校准模型的输出概率，GPT-2 和 GPT-3 的性能得到了显着提高。   3\tFramework of NSP-BERT NSP-BERT   3.1\tNext Sentence Prediction   NSP ——BERT模型的两个基本预训练任务之一，同时将两个句子 A 和 B 输入到 BERT 中，以预测句子 B 是否在同一文档中的句子 A 之后。 在特定训练中，有 50% 的时间，B 是 A 之后的实际下一个句子（IsNext），另外 50% 的时间，作者使用语料库中的随机句子（NotNext）。   (1)\t等式   \\[q_M(n_k|X_i)=\\frac{\\exp{s(n_k|x_i^{(1)},x_i^{(2)})}}{\\sum_{n}{\\exp{s(n|x_i^{(1)},x_i^{(2)})}}}\\]     $M$表示在大规模语料库上训练的模型。   $X_i{(1)}$ 和 $X_i{(2)}$ 分别表示句子 A 和句子 B。 模型的输入是 $X_{input}$，$q_M$ 表示模型的 NSP 头部的输出概率。   $s = W_{nsp}h_{[CLS]}$，其中 $h_{[CLS]}$ 是 [CLS] 的隐藏向量，$W_{nsp}$ 是 NSP 任务学习的矩阵，$W_{nsp} ∈ R^{2×H}$。                                   NSP 任务的损失函数 $L_{NSP} = − logq_M(n           x)$ ，其中 $n ∈ {IsNext, NotNext}$。                           (2)\tNSP任务不是确定两个短语的顺序，而是确定他们是否具有相同的主题   (3)\tNSP任务与对比学习任务非常相似具有逻辑推理能力：      NSP任务是interactive的，token不仅可以与本句子中的其他token交互，也可以和别的句子的token交互。   NSP 任务与 MLM 任务一起训练。 MLM任务为整个模型的self-attention机制提供了训练基础。   3.2\tPrompts in NSP-BERT   NSP-BERT 与其他基于提示的学习方法一样，需要为各种任务构建合适的模板。 由于 NSP-BERT 不依赖任何下游任务的训练数据，因此模板的构建形式必须与原始 NSP 任务紧密匹配。 本节展示如何为不同的任务构建模板。   (1)\tSingle Sentence Task   样本必须在单句任务中分类为不同的主题，比如情感分析是将文本分类为各种感情趋势。   假设单句分类任务的训练数据集D： \\(D = \\{(x_i,y_i)\\}_{i=1}^{N}\\)  $x_i$ 是总共 N 个样本中的第 i 个句子，$x_i$ 的标签为 $y_i$ ，可以映射到 $y ^{(j)} ∈ Y$，其中 $|Y| = M$，M 是这个数据集中的主题数。 对于每个 $y^{(j)} $，它将被映射到一个模板 $p^{(j)} ∈ P$。模型的输入将是: \\(X_{input} = [CLS]x_i[SEP]p^{(j)}[EOS]\\) 样本$x_i$的标签为$y^{(j)}$的概率： \\(q(y^{j}|x_i) = \\frac{\\exp{q_M(n=IsNext|x_i,p^{(j)})}}{\\sum_{p^{(k)}∈P}{\\exp{q_M(n=IsNext|x_i,p^{(k)})}}}\\)   (2)\tSentence Pair Task   句子对任务旨在识别两个句子之间的关系，这种类型的数据集$D={(x_i^{(1)},x_i^{(2)},y_i}_{i=1}^N$包含 N 个样本，每个样本有 2 个句子 $x _i^{(1)} $ 和$ x _i^{(2)} $。 它们之间的关系是 $y^i $，可以映射到 $y ^{(j)} ∈ Y$，其中$|Y| = M$，是关系类型的数量。NSP模型的输出为： \\(q(x_i)=q_M(n=IsNext|x_i^{(1)},x_i^{(2)})\\)   (3)\tCloze-Style Task   完形填空式任务是给出一个带有空格的句子，模型必须找到最合适的token或span来填充空格。   数据集$ D = {(x_i , c i^{(1)}  , …, c _i^{(j)} , …, y_i)}{i=1}^N$。对于每个样本，有一个 [BLANK] 的句子$ x_i$，并且有 $K_i $候选 ${c i^{(j)}  }{j=1}^{K_i} $可供选择。 对于每个选项$c_i^{(j)}$，都有一个模板 $p _i^{(j) } ∈ P_i$ 与之对应。 对于输入： \\(X_{input}=[CLS]x_i[SEP]p_i^{(j)}[EOS]\\) 输出模型： \\(q(y_i^{(j)}|x_i)=\\frac{\\exp{q_M(n=IsNext|x_i,p_i^{(j)})}}{\\sum{p_i^{(k)∈P_i}\\exp{q_M(n=IsNext|x_i,p_i^{(k)})}}}\\)    采用soft-position index，允许NSP像MLM一样工作，将候选词coin的位置索引与[BLANK]对齐。   (4)\tWord Sense Disambiguation   在完全监督的训练场景中，作者可以在单词前后添加标记来识别要消歧的单词。      因为没有用于句子级提示学习的下游任务训练数据，所以无法通过标记来识别目标词的位置。 论文提出了一种 TwoStage Prompt 构造方法，在NSP-BERT 中使用自然语言描述来指示目标词。      stage1：在句子 A 的末尾提示目标词。这个阶段的目的是为目标词提供足够的上下文。   stage2：提示对句子 B 中候选词义的描述。   将两阶段提示输入语言模型，判断句子是否流畅合理。 让 $p_{i,1}^{(j)}$ ,$p_{i,2}^{(j)}$ 表示提示的第一部分和第二部分。 模型的输入是： \\(X_{input}=[CLS]x_i,p_{i,1}^{(j)}[SEP]p_{i,2}^{(j)}[EOS]\\)   3.3\tAnswering Mapping   候选-对比答案映射和样本-对比答案映射      (1)\tCandidates-Contrast用于具有多个候选的数据集，例如候选情绪、候选主题、候选习语和候选实体。 对于上述数据集，有一个模板$p_i^{(j)}$(或$p_i$)对应标签$y_i^{(j)}$(或$y_i$)。 在条件为IsNext的情况下，将候选者中M输出的概率最高的作为最终输出答案： \\(\\hat{y_i}=\\arg{\\max_j{q(y_i^{(j)}|x_i)}}=\\arg{\\max_j{n=IsNext|x_i,p_i^{(j)})}}\\) (2)\tSample-Contrast针对没有对比候选的数据集，算法：      4\tExperiment   4.1\tTask and Datasets   在FewCLUE上评估模型，其中包含9 个中文NLU（自然语言理解） 任务，4 个单句任务、3 个句子对任务和2 个阅读理解任务。 数据集的详细信息显示在附录中。 每个训练集中的样本数量很少，每个标签对应8或16个样本。   DuEL2.0 为了进一步验证NSPBERT在词义消歧方面的能力，增加了实体链接数据集DuEL2.0。 特别地，作者将 DuEL2.0 分为两部分。 第一部分，实体链接部分，有26586个样本。 所有样本的mention 可以映射到知识库中的单个或多个实体，每个mention 平均可以链接到5.37 个实体。 第二部分，实体类型部分，有6465个样本。 这些样本的提及在知识库中是找不到的，但是它们会被划分到它们对应的上层实体类型中。 共有 24 种上层实体类型。   4.2\tBaselines   三个训练场景           Fine-Tuning 在FewCLUE 训练集上对预训练语言模型进行标准微调。 模型使用交叉熵损失进行微调，并使用 BERT 样式模型的隐藏向量 [CLS]，$h_{[CLS]}$ 和分类层$ softmax(Wh_{[CLS]})$，其中 $W ∈ R^{M×H}$，M 是数字 的标签。            Few-shot 选择token-level模型 PET其优化模型 ADAPET、P-tuning和 LM -BFF。 论文还选择句子级模型 EFL。 所有的小样本模型都是在FewCLUE 的训练集上训练的。            Zero-Shot 在零样本场景中，有两种实现方式，一种是使用 L2R LM 的 GPT-ZERO，另一种是使用 MLM 的 PET-ZERO。       4.3\texperiment settings   BERT 模型使用 RoBERTa-wwm-ext.   GPT 模型是 NEZHA-Gen 。论文采用了 UER 使用 MLM 和 NSP 训练的 vanilla BERT 。   预训练语料库是一个大型的中文混合语料库。 连同基本模型（L=12，H=768，A=12，总参数=110M），论文使用各种尺度（很小小、小和大）的UER-BERTs进行实验，以验证各种尺度模型在 NSP-BERT 上的效果 。   4.4\tMain Results     ","categories": [],
        "tags": [],
        "url": "/210903564/",
        "teaser": null
      },{
        "title": "",
        "excerpt":"PPT: Pre-trained Prompt Tuning for Few-shot Learning   针对小样本学习的预训练提示调优   abstract      通过弥合预训练任务和各种下游任务之间的差距，预训练语言模型 (PLM) 的提示显示出卓越的性能。   当下游数据充足时，即时调整的性能与传统的全模型微调相当，而在少样本学习设置下它的表现要差得多，这可能会阻碍即时调整在实践中的应用。这种低性能是因为初始化软提示的方式。   本文通过在预训练阶段添加软提示来预训练提示以获得更好的初始化，并将此预训练提示调优框架命名为“PPT”。   为了保证PPT的泛化性，作者将相似的分类任务制定成统一的任务形式，并为这个统一的任务预训练软提示。   1\tIntroduction   两种主流的FT方法：      面向任务的微调，在 PLM 之上添加一个特定于任务的头，然后通过优化在特定任务训练数据的特定任务学习目标来微调整个模型。   面向提示的微调，将数据样本转换为包含提示标记的线性化序列，并将所有下游任务形式化为语言建模问题。 与面向任务的微调相比，面向提示的微调在目标（掩码语言建模）方面更类似于预训练，从而有助于更好地利用 PLM 中的知识并经常获得更好的性能。   提示调整 (PT) ：   PT 使用由连续嵌入组成的软提示而不是硬提示（离散语言短语）。 这些连续提示嵌入通常是随机初始化和端到端学习的。 为了避免为每个下游任务存储整个模型，PT 冻结 PLM 的所有参数，仅调整软提示，而不添加任何中间层和特定于任务的组件。   本文广泛探索了如何通过 PT 以高效和有效的方式使用 PLM 进行小样本学习。   为了帮助模型找到合适的提示，我们在大规模未标记语料库上使用自监督任务预训练这些标记。为了确保预训练提示的泛化，我们将典型的分类任务分为三种格式：句子对分类、多项选择分类和单文本分类，每种格式对应一个自监督的预训练任务。此外，我们发现多选分类在这些格式中更为普遍，我们可以将所有下游分类任务统一为这种格式。我们将此预训练提示调优 (PPT) 框架命名为“PPT”。   2\tpilot experiments   本节在少样本设置下展示 PT 的几个试点实验。 作者凭经验分析了三种主要类别的提示增强策略的有效性，包括混合提示调整、语言表达选择和实词初始化。   (1)\tHybrid Prompt Tuning   在混合提示调整中，软提示标记和硬提示标记都被使用。 然而，以前的工作与整个模型一起训练软提示。 在 PT 的情况下，只有提示令牌是可调的，使用混合提示的有效性尚未得到充分探索。  此外，不同的硬模板对性能影响很大，需要大量人工进行提示设计和选择，为下一次调优提供了潜在的初始化。   (2)\tVerbalizer Selection   如何选择将特定任务标签映射到具体标记的语言器也值得研究。 不同的语言表达器选择对性能影响很大。 通常，解释相应标签含义的常用词效果很好。   (3)\tReal Word Initialization   对于具有 11B 参数的模型， 实词初始化对少镜头设置下的性能影响很小甚至是负面影响。 这表明对小模型的观察不能直接转移到大模型，并且为软提示标记找到一个好的初始化仍然至关重要。   3\tpre-trained prompt tuning(PPT)   3.1\tOverview   遵循 T5 和 PT 的方法，我们以文本到文本的格式解决所有下游任务。为了缩小预训练和下游任务之间的目标差距，prompt-oriented 微调将下游任务转换为一些完形填空式的目标。   以分类任务为例：   给定输入句子 $x ∈ \\mathcal{V}^∗$ 及其标签 $y ∈\\mathcal{ Y}$，首先应用模式映射$ f :\\mathcal{ V}^∗→ \\mathcal{V}^∗ $将 x 转换为新的标记序列 f(x)， 其中 $ \\mathcal{V}$ 是 PLM 的词汇表。 f(x) 不仅添加了一些提示标记作为提示，而且还保留了至少一个屏蔽token $&lt;\\mathbf{X}&gt;$ 以让 PLM 预测屏蔽位置处的标记。 然后，使用语言表达器$ v :\\mathcal{ y}→ \\mathcal{V}^∗ $ 将 y 映射到标签token序列 v(y)。 使用 f(·) 和 v(·)，分类任务可以用模式-语言表达器对 (f, v) 表示：      其中 θ 表示所有可调参数。使用“PVP”来表示这个模式-言语者(verbalizer)对。   在 PT 中，一组软提示标记 P 连接到序列的前面，模型输入变为 [P ; f(x)]，其中 [·; ·] 是连接函数。 通过在固定其他参数的情况下单独调整 P，方程(1) 被替换为：      最近，预训练已被证明是找到一个好的模型初始化的有效方法。 受此启发，我们建议对软提示进行预训练。 由 NSP 预训练的软提示可以很好地初始化这些句子对任务。   形式上，将下游任务分成 m 个组 ${\\mathcal{T}1,\\mathcal{ T}_2, …,\\mathcal{ T}_m}$，其中$\\mathcal{ T}_i$ 是包含 $n_i$ 个下游任务的集合：${PVP^1_i ,PVP^2_i , …, PVP^{n_i} i }$，其中 $PVP^k_i = (f^k_i , v^k_ i )$。 对于每一组，我们设计一个相应的预训练任务 $PVP^{pre}_ i = (f^{pre}_ i , v ^{pre}_ i )$。 在所有模型参数固定的这些预训练任务上预训练软提示后，我们得到 m 个预训练提示 ${P_1, P_2, …, P_m}$。 预训练后，对于 $\\mathcal{T}i$ 中的每个任务 $PVP^k i$，我们继续优化方程(2)通过使用$P_i$作为软提示的初始化。   3.2\tDesigning Pattern-Verbalizer Pairs for Pre-training   3.2.1\tSentence-Pair Classification                  以两个句子$ x = (s1, s2)$ ，将标签 $\\mathcal{Y} = [0, 1, 2]$ 的 3 类分类作为预训练任务。 Y中的这些标签可以分别表示两个句子之间的语义关系是连贯的、相似的和不相关的。 为了从未标记的纯文本文档中构造信号，我们将相邻的两个句子设为标签 2，来自同一文档但不相邻的设为 1，来自不同文档的设为 0。我们考虑标签集 $       \\mathcal{Y}       &lt;= 3$， 因为这涵盖了大多数句子对任务。 $PVP^{pre}_ i = (f^{ pre}_ i , v^{pre}_i )$ 给出如下：              根据 $PVP^{pre}_ i$ 设计 $PVP^k_ i = (f^ k_ i , v^k i )$ 很简单。 $s_1$ 和 $s_2$ 可以用输入句对代替。 如果一个任务输出两个标签，那么我们取$ v^ k i (\\mathcal{Y}) = [no, yes]$。 如果一个任务输出三个标签，我们设置 $v^ k_ i = v^{pre}_ i$ 。 如果一个任务需要测量两个句子之间的相似度，{no, yes} 的概率可以用于这个任务。   3.2.2\tMultiple-Choice Classification   许多任务可以表述为多项选择分类，它以一个查询和几个候选答案作为输入。   我们设计了一个下一句选择任务来预训练提示。 给定一个句子作为查询 $s_q$，模型被训练从六个候选中选择相邻的句子，表示为 $s_1 ∼ s_6$，因此标签集是 $\\mathcal{Y} = [1, 2, 3, 4, 5, 6]$。 这些候选包括正确答案、来自同一文档但不与查询相邻的一个句子以及来自其他文档的四个句子。 对于 $x = (s_q, s_1, s_2, · · · , s_6), (f ^{pre}_ i , v ^{pre}_ i )$ 给出为：      大多数多项选择任务可以直接使用${f ^{pre}_i , v ^{pre} _i }$ 作为它们的 PVP。 对于阅读理解等任务，输入可能包含一段话和一个问题。 我们将它们连接起来形成一个查询。   3.2.3\tSingle-Sentence Classification   对于单句分类，我们为提示预训练创建了伪标签。 以情感分类为例，我们使用另一个小模型对来自预训练语料库的句子进行情感标签标注，过滤掉分类概率较低的句子。 在实践中，我们使用 RoBERTaBASE  模型在 5 类情感分类数据集上进行了微调，而不是我们测试的小样本数据集。 然后使用语料库中的句子 $s$，我们有输入 $x = (s) $和标签集 $\\mathcal{Y} = [1, 2, 3, 4, 5]$。 $(f^{pre} _i , v ^{pre} _i )$ 给出为：      对于有 5 个标签的情感分类任务，我们可以使用 $PVP^k_ i = PVP^{pre}_ i$ 。 对于那些标签少于 5 个的任务，我们从 $v ^{pre}_ i (\\mathcal{Y})$ 中选择一个子集作为标签。   3.3\tUnifying Task Formats   上述用于预训练的 PVP 可以统一为一个格式：多选分类。 具体来说，对于句子对分类任务，查询是两个句子的连接，有三个选项：no、maybe 和 yes。 对于单句分类，查询是输入的句子，选项是具体的标签。   4\tExperiments   4.1\tSetup           对中文和英文任务进行了实验。对于少于 5 个标签的任务，我们使用来自原始训练数据的 32 个样本构建训练和验证集，并确保标签数量平衡。对于 超过 5 个标签的任务，为每个标签随机选择 8 个样本。            对于英语数据集，我们使用具有 11B 个参数的 T5-XXL 作为我们的基础模型来进行 PT。对于中文数据集，我们基于 CPM-2 进行 PT。由于 CPM-2 不提供其他尺寸的模型，我们将其与各种尺寸的 mT5进行比较。            我们始终为 PT 使用 100 个软令牌。结果，可调参数只有 100×4096 = 4.1 × 10^6 = 410K。与 FT 的 11B（1.1×10^10）参数相比，PT 只需要为每个任务存储 3000 倍小的参数。       4.2\tMain Results   Effectiveness      随着参数数量的增加，FT的性能有所提升。 这意味着大规模模型仍然有助于小样本学习。   PPT 在大多数数据集中明显优于 Vanilla PT 和 LM Adaption。   PPT 在所有中文数据集和大多数英文数据集上的 10B 模型上优于 FT。 这表明掩码语言建模和下游任务之间仍然存在差距。   PPT 在大多数数据集上导致较低的方差。 在预训练的帮助下，所有数据集的方差都保持在较低水平。   5\tConclusion   本文介绍了 PPT，这是一个改进小样本学习的快速调整的框架。 我们建议首先将下游任务统一为多种格式。 然后，我们为每种格式设计自我监督的预训练任务，并对这些任务的提示进行预训练。 最后，我们根据相应预训练提示的初始化对下游任务进行提示调整。 大量实验表明，我们的方法明显优于其他即时调整基线，性能与全模型调整相当甚至更好。   未来的工作有两个重要方向：（1）为其他类型的任务（如语言生成和关系提取）设计统一的任务格式和相应的预训练目标。 (2) 除软提示外，统一任务预训练是否有助于预训练语言模型本身。   ","categories": [],
        "tags": [],
        "url": "/210904332/",
        "teaser": null
      },]
